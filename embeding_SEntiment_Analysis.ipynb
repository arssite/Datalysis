{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNmUx8Fnv+tKhGtthzLeFtP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arssite/Datalysis/blob/main/embeding_SEntiment_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Embedding\n",
        "It is a technique in deep learning used to represent categorical variables as vectors of real numbers. This allows the model to learn relationships between different categories and use them for prediction or classification tasks.\n",
        "\n",
        "Benefits of using embedding:\n",
        "\n",
        "Reduced dimensionality: Embeddings are typically lower-dimensional than the original categorical variables, which can improve computational efficiency and reduce overfitting.\n",
        "Improved interpretability: Embeddings can be visualized to understand the relationships between different categories.\n",
        "Increased flexibility: Embeddings can be used with a variety of deep learning models, including convolutional neural networks (CNNs) and recurrent neural networks (RNNs).\n",
        "How embedding works:\n",
        "\n",
        "One-hot encoding: The first step is to convert the categorical variables into one-hot encoded vectors. This means that each category is represented by a vector of zeros, except for the position corresponding to the category, which is set to 1.\n",
        "Embedding layer: The one-hot encoded vectors are then passed through an embedding layer. This layer is a neural network that learns a mapping from the one-hot encoded vectors to a lower-dimensional space.\n",
        "Output: The output of the embedding layer is a vector of real numbers for each category. These vectors can then be used as input to other deep learning models.\n",
        "Applications of embedding:\n",
        "\n",
        "Natural language processing: Embeddings are commonly used in natural language processing tasks such as sentiment analysis, text classification, and machine translation.\n",
        "Computer vision: Embeddings can also be used in computer vision tasks such as image classification and object detection.\n",
        "Recommendation systems: Embeddings can be used to learn user preferences and recommend items that the user is likely to be interested in."
      ],
      "metadata": {
        "id": "zZXM7oHyrC_S"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "uYxEVxf-qoMY"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "docs = [\n",
        "    \"The quick brown fox jumps over the lazy dog.\",\n",
        "    \"Lorem ipsum dolor sit amet, consectetur adipiscing elit.\",\n",
        "    \"Python is a high-level programming language.\",\n",
        "    \"Stack Overflow is a question and answer website for professional and enthusiast programmers.\",\n",
        "    \"Artificial intelligence is reshaping industries across the globe.\",\n",
        "    \"The universe is vast and full of mysteries.\",\n",
        "    \"Climate change is a pressing issue that requires global cooperation.\",\n",
        "    \"The sun rises in the east and sets in the west.\",\n",
        "    \"Music has the power to evoke strong emotions.\",\n",
        "    \"Education is the key to unlocking opportunities.\",\n",
        "    \"Health is wealth.\",\n",
        "    \"The journey of a thousand miles begins with a single step.\",\n",
        "    \"Reading is to the mind what exercise is to the body.\",\n",
        "    \"Life is like a box of chocolates; you never know what you're gonna get.\",\n",
        "    \"Laughter is the best medicine.\",\n",
        "    \"The only way to do great work is to love what you do.\",\n",
        "    \"Success is not final, failure is not fatal: It is the courage to continue that counts.\",\n",
        "    \"Believe you can and you're halfway there.\",\n",
        "    \"Yesterday is history, tomorrow is a mystery, but today is a gift. That is why it is called the present.\",\n",
        "    \"Happiness is not something ready made. It comes from your own actions.\",\n",
        "    \"Be yourself; everyone else is already taken.\",\n",
        "    \"In three words I can sum up everything I've learned about life: it goes on.\",\n",
        "    \"To be yourself in a world that is constantly trying to make you something else is the greatest accomplishment.\",\n",
        "    \"Life is either a daring adventure or nothing at all.\",\n",
        "    \"Success is not the key to happiness. Happiness is the key to success. If you love what you are doing, you will be successful.\",\n",
        "    \"Don't cry because it's over, smile because it happened.\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "token=Tokenizer()"
      ],
      "metadata": {
        "id": "9ISyNnIWquKi"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token.fit_on_texts(docs)"
      ],
      "metadata": {
        "id": "6szSJJr2qx_p"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(token.word_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lvXJVF62sBhy",
        "outputId": "b045a56a-827f-4efe-f294-318fbec415d0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "175"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token.word_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXFi6HUTrWVB",
        "outputId": "c96bc0ce-310a-4e6e-843a-4c533175da9f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'is': 1,\n",
              " 'the': 2,\n",
              " 'to': 3,\n",
              " 'a': 4,\n",
              " 'you': 5,\n",
              " 'and': 6,\n",
              " 'it': 7,\n",
              " 'that': 8,\n",
              " 'in': 9,\n",
              " 'what': 10,\n",
              " 'not': 11,\n",
              " 'of': 12,\n",
              " 'key': 13,\n",
              " 'life': 14,\n",
              " 'success': 15,\n",
              " 'happiness': 16,\n",
              " 'be': 17,\n",
              " 'over': 18,\n",
              " \"you're\": 19,\n",
              " 'do': 20,\n",
              " 'love': 21,\n",
              " 'can': 22,\n",
              " 'something': 23,\n",
              " 'yourself': 24,\n",
              " 'else': 25,\n",
              " 'because': 26,\n",
              " 'quick': 27,\n",
              " 'brown': 28,\n",
              " 'fox': 29,\n",
              " 'jumps': 30,\n",
              " 'lazy': 31,\n",
              " 'dog': 32,\n",
              " 'lorem': 33,\n",
              " 'ipsum': 34,\n",
              " 'dolor': 35,\n",
              " 'sit': 36,\n",
              " 'amet': 37,\n",
              " 'consectetur': 38,\n",
              " 'adipiscing': 39,\n",
              " 'elit': 40,\n",
              " 'python': 41,\n",
              " 'high': 42,\n",
              " 'level': 43,\n",
              " 'programming': 44,\n",
              " 'language': 45,\n",
              " 'stack': 46,\n",
              " 'overflow': 47,\n",
              " 'question': 48,\n",
              " 'answer': 49,\n",
              " 'website': 50,\n",
              " 'for': 51,\n",
              " 'professional': 52,\n",
              " 'enthusiast': 53,\n",
              " 'programmers': 54,\n",
              " 'artificial': 55,\n",
              " 'intelligence': 56,\n",
              " 'reshaping': 57,\n",
              " 'industries': 58,\n",
              " 'across': 59,\n",
              " 'globe': 60,\n",
              " 'universe': 61,\n",
              " 'vast': 62,\n",
              " 'full': 63,\n",
              " 'mysteries': 64,\n",
              " 'climate': 65,\n",
              " 'change': 66,\n",
              " 'pressing': 67,\n",
              " 'issue': 68,\n",
              " 'requires': 69,\n",
              " 'global': 70,\n",
              " 'cooperation': 71,\n",
              " 'sun': 72,\n",
              " 'rises': 73,\n",
              " 'east': 74,\n",
              " 'sets': 75,\n",
              " 'west': 76,\n",
              " 'music': 77,\n",
              " 'has': 78,\n",
              " 'power': 79,\n",
              " 'evoke': 80,\n",
              " 'strong': 81,\n",
              " 'emotions': 82,\n",
              " 'education': 83,\n",
              " 'unlocking': 84,\n",
              " 'opportunities': 85,\n",
              " 'health': 86,\n",
              " 'wealth': 87,\n",
              " 'journey': 88,\n",
              " 'thousand': 89,\n",
              " 'miles': 90,\n",
              " 'begins': 91,\n",
              " 'with': 92,\n",
              " 'single': 93,\n",
              " 'step': 94,\n",
              " 'reading': 95,\n",
              " 'mind': 96,\n",
              " 'exercise': 97,\n",
              " 'body': 98,\n",
              " 'like': 99,\n",
              " 'box': 100,\n",
              " 'chocolates': 101,\n",
              " 'never': 102,\n",
              " 'know': 103,\n",
              " 'gonna': 104,\n",
              " 'get': 105,\n",
              " 'laughter': 106,\n",
              " 'best': 107,\n",
              " 'medicine': 108,\n",
              " 'only': 109,\n",
              " 'way': 110,\n",
              " 'great': 111,\n",
              " 'work': 112,\n",
              " 'final': 113,\n",
              " 'failure': 114,\n",
              " 'fatal': 115,\n",
              " 'courage': 116,\n",
              " 'continue': 117,\n",
              " 'counts': 118,\n",
              " 'believe': 119,\n",
              " 'halfway': 120,\n",
              " 'there': 121,\n",
              " 'yesterday': 122,\n",
              " 'history': 123,\n",
              " 'tomorrow': 124,\n",
              " 'mystery': 125,\n",
              " 'but': 126,\n",
              " 'today': 127,\n",
              " 'gift': 128,\n",
              " 'why': 129,\n",
              " 'called': 130,\n",
              " 'present': 131,\n",
              " 'ready': 132,\n",
              " 'made': 133,\n",
              " 'comes': 134,\n",
              " 'from': 135,\n",
              " 'your': 136,\n",
              " 'own': 137,\n",
              " 'actions': 138,\n",
              " 'everyone': 139,\n",
              " 'already': 140,\n",
              " 'taken': 141,\n",
              " 'three': 142,\n",
              " 'words': 143,\n",
              " 'i': 144,\n",
              " 'sum': 145,\n",
              " 'up': 146,\n",
              " 'everything': 147,\n",
              " \"i've\": 148,\n",
              " 'learned': 149,\n",
              " 'about': 150,\n",
              " 'goes': 151,\n",
              " 'on': 152,\n",
              " 'world': 153,\n",
              " 'constantly': 154,\n",
              " 'trying': 155,\n",
              " 'make': 156,\n",
              " 'greatest': 157,\n",
              " 'accomplishment': 158,\n",
              " 'either': 159,\n",
              " 'daring': 160,\n",
              " 'adventure': 161,\n",
              " 'or': 162,\n",
              " 'nothing': 163,\n",
              " 'at': 164,\n",
              " 'all': 165,\n",
              " 'if': 166,\n",
              " 'are': 167,\n",
              " 'doing': 168,\n",
              " 'will': 169,\n",
              " 'successful': 170,\n",
              " \"don't\": 171,\n",
              " 'cry': 172,\n",
              " \"it's\": 173,\n",
              " 'smile': 174,\n",
              " 'happened': 175}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token.word_counts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W23XyWaorYXY",
        "outputId": "e4bcad49-d7c4-49ff-de39-814bcb9b1fe1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('the', 19),\n",
              "             ('quick', 1),\n",
              "             ('brown', 1),\n",
              "             ('fox', 1),\n",
              "             ('jumps', 1),\n",
              "             ('over', 2),\n",
              "             ('lazy', 1),\n",
              "             ('dog', 1),\n",
              "             ('lorem', 1),\n",
              "             ('ipsum', 1),\n",
              "             ('dolor', 1),\n",
              "             ('sit', 1),\n",
              "             ('amet', 1),\n",
              "             ('consectetur', 1),\n",
              "             ('adipiscing', 1),\n",
              "             ('elit', 1),\n",
              "             ('python', 1),\n",
              "             ('is', 27),\n",
              "             ('a', 10),\n",
              "             ('high', 1),\n",
              "             ('level', 1),\n",
              "             ('programming', 1),\n",
              "             ('language', 1),\n",
              "             ('stack', 1),\n",
              "             ('overflow', 1),\n",
              "             ('question', 1),\n",
              "             ('and', 5),\n",
              "             ('answer', 1),\n",
              "             ('website', 1),\n",
              "             ('for', 1),\n",
              "             ('professional', 1),\n",
              "             ('enthusiast', 1),\n",
              "             ('programmers', 1),\n",
              "             ('artificial', 1),\n",
              "             ('intelligence', 1),\n",
              "             ('reshaping', 1),\n",
              "             ('industries', 1),\n",
              "             ('across', 1),\n",
              "             ('globe', 1),\n",
              "             ('universe', 1),\n",
              "             ('vast', 1),\n",
              "             ('full', 1),\n",
              "             ('of', 3),\n",
              "             ('mysteries', 1),\n",
              "             ('climate', 1),\n",
              "             ('change', 1),\n",
              "             ('pressing', 1),\n",
              "             ('issue', 1),\n",
              "             ('that', 4),\n",
              "             ('requires', 1),\n",
              "             ('global', 1),\n",
              "             ('cooperation', 1),\n",
              "             ('sun', 1),\n",
              "             ('rises', 1),\n",
              "             ('in', 4),\n",
              "             ('east', 1),\n",
              "             ('sets', 1),\n",
              "             ('west', 1),\n",
              "             ('music', 1),\n",
              "             ('has', 1),\n",
              "             ('power', 1),\n",
              "             ('to', 11),\n",
              "             ('evoke', 1),\n",
              "             ('strong', 1),\n",
              "             ('emotions', 1),\n",
              "             ('education', 1),\n",
              "             ('key', 3),\n",
              "             ('unlocking', 1),\n",
              "             ('opportunities', 1),\n",
              "             ('health', 1),\n",
              "             ('wealth', 1),\n",
              "             ('journey', 1),\n",
              "             ('thousand', 1),\n",
              "             ('miles', 1),\n",
              "             ('begins', 1),\n",
              "             ('with', 1),\n",
              "             ('single', 1),\n",
              "             ('step', 1),\n",
              "             ('reading', 1),\n",
              "             ('mind', 1),\n",
              "             ('what', 4),\n",
              "             ('exercise', 1),\n",
              "             ('body', 1),\n",
              "             ('life', 3),\n",
              "             ('like', 1),\n",
              "             ('box', 1),\n",
              "             ('chocolates', 1),\n",
              "             ('you', 7),\n",
              "             ('never', 1),\n",
              "             ('know', 1),\n",
              "             (\"you're\", 2),\n",
              "             ('gonna', 1),\n",
              "             ('get', 1),\n",
              "             ('laughter', 1),\n",
              "             ('best', 1),\n",
              "             ('medicine', 1),\n",
              "             ('only', 1),\n",
              "             ('way', 1),\n",
              "             ('do', 2),\n",
              "             ('great', 1),\n",
              "             ('work', 1),\n",
              "             ('love', 2),\n",
              "             ('success', 3),\n",
              "             ('not', 4),\n",
              "             ('final', 1),\n",
              "             ('failure', 1),\n",
              "             ('fatal', 1),\n",
              "             ('it', 5),\n",
              "             ('courage', 1),\n",
              "             ('continue', 1),\n",
              "             ('counts', 1),\n",
              "             ('believe', 1),\n",
              "             ('can', 2),\n",
              "             ('halfway', 1),\n",
              "             ('there', 1),\n",
              "             ('yesterday', 1),\n",
              "             ('history', 1),\n",
              "             ('tomorrow', 1),\n",
              "             ('mystery', 1),\n",
              "             ('but', 1),\n",
              "             ('today', 1),\n",
              "             ('gift', 1),\n",
              "             ('why', 1),\n",
              "             ('called', 1),\n",
              "             ('present', 1),\n",
              "             ('happiness', 3),\n",
              "             ('something', 2),\n",
              "             ('ready', 1),\n",
              "             ('made', 1),\n",
              "             ('comes', 1),\n",
              "             ('from', 1),\n",
              "             ('your', 1),\n",
              "             ('own', 1),\n",
              "             ('actions', 1),\n",
              "             ('be', 3),\n",
              "             ('yourself', 2),\n",
              "             ('everyone', 1),\n",
              "             ('else', 2),\n",
              "             ('already', 1),\n",
              "             ('taken', 1),\n",
              "             ('three', 1),\n",
              "             ('words', 1),\n",
              "             ('i', 1),\n",
              "             ('sum', 1),\n",
              "             ('up', 1),\n",
              "             ('everything', 1),\n",
              "             (\"i've\", 1),\n",
              "             ('learned', 1),\n",
              "             ('about', 1),\n",
              "             ('goes', 1),\n",
              "             ('on', 1),\n",
              "             ('world', 1),\n",
              "             ('constantly', 1),\n",
              "             ('trying', 1),\n",
              "             ('make', 1),\n",
              "             ('greatest', 1),\n",
              "             ('accomplishment', 1),\n",
              "             ('either', 1),\n",
              "             ('daring', 1),\n",
              "             ('adventure', 1),\n",
              "             ('or', 1),\n",
              "             ('nothing', 1),\n",
              "             ('at', 1),\n",
              "             ('all', 1),\n",
              "             ('if', 1),\n",
              "             ('are', 1),\n",
              "             ('doing', 1),\n",
              "             ('will', 1),\n",
              "             ('successful', 1),\n",
              "             (\"don't\", 1),\n",
              "             ('cry', 1),\n",
              "             ('because', 2),\n",
              "             (\"it's\", 1),\n",
              "             ('smile', 1),\n",
              "             ('happened', 1)])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token.document_count"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qWr8knN_rcEY",
        "outputId": "0dc93e16-5eb8-448d-a12e-dd6c60492edc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "26"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq=token.texts_to_sequences(docs)\n",
        "seq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_i40d333sKio",
        "outputId": "6f743efa-b316-4838-f4a6-24893628b697"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[2, 27, 28, 29, 30, 18, 2, 31, 32],\n",
              " [33, 34, 35, 36, 37, 38, 39, 40],\n",
              " [41, 1, 4, 42, 43, 44, 45],\n",
              " [46, 47, 1, 4, 48, 6, 49, 50, 51, 52, 6, 53, 54],\n",
              " [55, 56, 1, 57, 58, 59, 2, 60],\n",
              " [2, 61, 1, 62, 6, 63, 12, 64],\n",
              " [65, 66, 1, 4, 67, 68, 8, 69, 70, 71],\n",
              " [2, 72, 73, 9, 2, 74, 6, 75, 9, 2, 76],\n",
              " [77, 78, 2, 79, 3, 80, 81, 82],\n",
              " [83, 1, 2, 13, 3, 84, 85],\n",
              " [86, 1, 87],\n",
              " [2, 88, 12, 4, 89, 90, 91, 92, 4, 93, 94],\n",
              " [95, 1, 3, 2, 96, 10, 97, 1, 3, 2, 98],\n",
              " [14, 1, 99, 4, 100, 12, 101, 5, 102, 103, 10, 19, 104, 105],\n",
              " [106, 1, 2, 107, 108],\n",
              " [2, 109, 110, 3, 20, 111, 112, 1, 3, 21, 10, 5, 20],\n",
              " [15, 1, 11, 113, 114, 1, 11, 115, 7, 1, 2, 116, 3, 117, 8, 118],\n",
              " [119, 5, 22, 6, 19, 120, 121],\n",
              " [122,\n",
              "  1,\n",
              "  123,\n",
              "  124,\n",
              "  1,\n",
              "  4,\n",
              "  125,\n",
              "  126,\n",
              "  127,\n",
              "  1,\n",
              "  4,\n",
              "  128,\n",
              "  8,\n",
              "  1,\n",
              "  129,\n",
              "  7,\n",
              "  1,\n",
              "  130,\n",
              "  2,\n",
              "  131],\n",
              " [16, 1, 11, 23, 132, 133, 7, 134, 135, 136, 137, 138],\n",
              " [17, 24, 139, 25, 1, 140, 141],\n",
              " [9, 142, 143, 144, 22, 145, 146, 147, 148, 149, 150, 14, 7, 151, 152],\n",
              " [3, 17, 24, 9, 4, 153, 8, 1, 154, 155, 3, 156, 5, 23, 25, 1, 2, 157, 158],\n",
              " [14, 1, 159, 4, 160, 161, 162, 163, 164, 165],\n",
              " [15,\n",
              "  1,\n",
              "  11,\n",
              "  2,\n",
              "  13,\n",
              "  3,\n",
              "  16,\n",
              "  16,\n",
              "  1,\n",
              "  2,\n",
              "  13,\n",
              "  3,\n",
              "  15,\n",
              "  166,\n",
              "  5,\n",
              "  21,\n",
              "  10,\n",
              "  5,\n",
              "  167,\n",
              "  168,\n",
              "  5,\n",
              "  169,\n",
              "  17,\n",
              "  170],\n",
              " [171, 172, 26, 173, 18, 174, 26, 7, 175]]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import pad_sequences\n",
        "sequences = pad_sequences(seq,padding='post')\n",
        "sequences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dPcQ6s-dsOCC",
        "outputId": "9d9225d2-1803-48b6-c3dd-6a01677de868"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  2,  27,  28,  29,  30,  18,   2,  31,  32,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [ 33,  34,  35,  36,  37,  38,  39,  40,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [ 41,   1,   4,  42,  43,  44,  45,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [ 46,  47,   1,   4,  48,   6,  49,  50,  51,  52,   6,  53,  54,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [ 55,  56,   1,  57,  58,  59,   2,  60,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  2,  61,   1,  62,   6,  63,  12,  64,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [ 65,  66,   1,   4,  67,  68,   8,  69,  70,  71,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  2,  72,  73,   9,   2,  74,   6,  75,   9,   2,  76,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [ 77,  78,   2,  79,   3,  80,  81,  82,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [ 83,   1,   2,  13,   3,  84,  85,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [ 86,   1,  87,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  2,  88,  12,   4,  89,  90,  91,  92,   4,  93,  94,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [ 95,   1,   3,   2,  96,  10,  97,   1,   3,   2,  98,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [ 14,   1,  99,   4, 100,  12, 101,   5, 102, 103,  10,  19, 104,\n",
              "        105,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [106,   1,   2, 107, 108,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  2, 109, 110,   3,  20, 111, 112,   1,   3,  21,  10,   5,  20,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [ 15,   1,  11, 113, 114,   1,  11, 115,   7,   1,   2, 116,   3,\n",
              "        117,   8, 118,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [119,   5,  22,   6,  19, 120, 121,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [122,   1, 123, 124,   1,   4, 125, 126, 127,   1,   4, 128,   8,\n",
              "          1, 129,   7,   1, 130,   2, 131,   0,   0,   0,   0],\n",
              "       [ 16,   1,  11,  23, 132, 133,   7, 134, 135, 136, 137, 138,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [ 17,  24, 139,  25,   1, 140, 141,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  9, 142, 143, 144,  22, 145, 146, 147, 148, 149, 150,  14,   7,\n",
              "        151, 152,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  3,  17,  24,   9,   4, 153,   8,   1, 154, 155,   3, 156,   5,\n",
              "         23,  25,   1,   2, 157, 158,   0,   0,   0,   0,   0],\n",
              "       [ 14,   1, 159,   4, 160, 161, 162, 163, 164, 165,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [ 15,   1,  11,   2,  13,   3,  16,  16,   1,   2,  13,   3,  15,\n",
              "        166,   5,  21,  10,   5, 167, 168,   5, 169,  17, 170],\n",
              "       [171, 172,  26, 173,  18, 174,  26,   7, 175,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]],\n",
              "      dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import imdb\n",
        "from keras import Sequential\n",
        "from keras.layers import Dense,SimpleRNN,Embedding,Flatten"
      ],
      "metadata": {
        "id": "avgHnIxhsXTo"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=Sequential()\n",
        "model.add(Embedding(17,output_dim=2,input_length=5))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cu2LKlmdscTf",
        "outputId": "0b2009a0-b66b-44cb-f752-998a91913474"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 5, 2)              34        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 34 (136.00 Byte)\n",
            "Trainable params: 34 (136.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "SlEqb1lqsjF_"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pAq44vtLtu8k"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}