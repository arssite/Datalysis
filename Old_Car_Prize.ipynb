{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNoW3XlKscliYKA4STKErFx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arssite/Datalysis/blob/main/Old_Car_Prize.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q: Write a program to find old car prize using ANN Technique."
      ],
      "metadata": {
        "id": "XXgZHFkBsa-P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To create a program to predict the price of old cars using Artificial Neural Networks (ANN) and a dataset from Kaggle, you can follow these steps:\n",
        "\n",
        "________________________________________________________________________\n",
        "Acquire the Dataset: Download the dataset from Kaggle or any other reliable source. Ensure it contains relevant features like car make, model, year, mileage, etc., along with the prices.\n",
        "\n",
        "Preprocess the Data: Clean the dataset by handling missing values, encoding categorical variables, and scaling numerical features if necessary.\n",
        "Split the Dataset: Divide the dataset into training and testing sets to evaluate the performance of the model.\n",
        "\n",
        "Build the ANN Model: Create an Artificial Neural Network model using libraries like TensorFlow or Keras. Define the architecture, including the number of layers, neurons, activation functions, and optimization algorithm.\n",
        "\n",
        "Train the Model: Feed the training data into the ANN model and adjust the weights iteratively to minimize the loss function.\n",
        "\n",
        "Evaluate the Model: Assess the model's performance using the testing data. Calculate metrics like Mean Squared Error (MSE) or Root Mean Squared Error (RMSE) to measure the prediction accuracy.\n",
        "\n",
        "Make Predictions: Use the trained model to predict the prices of old cars based on new data."
      ],
      "metadata": {
        "id": "RAChv7bhsy5v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense"
      ],
      "metadata": {
        "id": "lP2uleG1trBp"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Link dataset : https://www.kaggle.com/datasets/yashpaloswal/ann-car-sales-price-prediction"
      ],
      "metadata": {
        "id": "ApJEqOqdt0kP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "dataset = pd.read_csv('car_dataset.csv')"
      ],
      "metadata": {
        "id": "zULJ0UhVttTX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess the data\n",
        "# Perform data cleaning, encoding, and feature scaling\n",
        "\n",
        "# Split the dataset into features (X) and target variable (y)\n",
        "X = dataset.drop(columns=['price'])  # Features\n",
        "y = dataset['price']  # Target variable\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "nziLZspVt7rg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature Scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "FLXoMGq_t-Ng"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the ANN model\n",
        "model = Sequential([\n",
        "    Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(1)  # Output layer\n",
        "])"
      ],
      "metadata": {
        "id": "5qXMD0OXuArX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import plot_model\n",
        "plot_model(model)"
      ],
      "metadata": {
        "id": "8TnK_V-muM7_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mse')\n"
      ],
      "metadata": {
        "id": "7CKHJ0I2uDen"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model.fit(X_train_scaled, y_train, epochs=100, batch_size=32, validation_split=0.2)\n"
      ],
      "metadata": {
        "id": "pKFYMyWbuE_v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "loss = model.evaluate(X_test_scaled, y_test)\n",
        "print(\"Mean Squared Error on Test Data:\", loss)"
      ],
      "metadata": {
        "id": "6ksS5qQ7uGSx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions\n",
        "predictions = model.predict(X_test_scaled)"
      ],
      "metadata": {
        "id": "SwKo5tUxuHbw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example of using the trained model to predict the price of a new car\n",
        "new_car_features = np.array([[...]])  # Replace '...' with the features of the new car\n",
        "scaled_features = scaler.transform(new_car_features)\n",
        "predicted_price = model.predict(scaled_features)\n",
        "print(\"Predicted Price of the New Car:\", predicted_price)"
      ],
      "metadata": {
        "id": "NNUMd1tLuJKg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1t33eW8MsaZ2"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jyclmjs9t_9g"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}